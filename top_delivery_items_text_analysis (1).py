# -*- coding: utf-8 -*-
"""Top Delivery Items Text Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/133FoVSU7wxPdMSYBR4Hq3Ff5rbauMwsN
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

df = pd.read_excel('Highest Receipt Delivery Orders.xlsx')
df

import gensim
from gensim import corpora, models

docs = df['Items Purchased']
docs

corpus = [doc.split() for doc in docs]
corpus

dictionary = corpora.Dictionary(corpus)

DFM = [dictionary.doc2bow(doc) for doc in corpus]

term_maps = dictionary.token2id

term_maps = {v: k for k, v in term_maps.items()}
term_maps

myDFM = pd.DataFrame(
    gensim.matutils.corpus2csc(DFM).T.toarray()).rename(columns=term_maps)

myDFM

myDFM.sum().sort_values(ascending=False)

df['Cleaned Text'] = df['Items Purchased'].str.replace(r'[^\w\s]+','')

df['Cleaned Text']

import nltk
nltk.download('stopwords')

from nltk.corpus import stopwords
stop = stopwords.words('english')
df['Cleaned Text']=df['Cleaned Text'].apply(
    lambda x: " " .join(x for x in x.split() if x not in stop))

df['Cleaned Text']

df['Cleaned Text']=df['Cleaned Text'].apply(
    lambda x: " ".join(x.lower() for x in x.split()))

df['Cleaned Text']

docs_clean = df['Cleaned Text']
corpus_clean = [doc.split() for doc in docs_clean]
dictionary_clean = corpora.Dictionary(corpus_clean)
DFM_clean=[dictionary_clean.doc2bow(doc) for doc in corpus_clean]

term_maps = dictionary_clean.token2id
term_maps = {v:k for k, v in term_maps.items()}
term_maps

myDFM_clean = pd.DataFrame(
    gensim.matutils.corpus2csc(DFM_clean).T.toarray()).rename(columns=term_maps)

myDFM_clean

tfidf = gensim.models.TfidfModel(DFM_clean)
DFM_tfidf=tfidf[DFM_clean]

myDFM_clean = pd.DataFrame(
gensim.matutils.corpus2csc(DFM_clean).T.toarray()).rename(columns
= term_maps)
myDFM_clean

SVD_model = gensim.models.LsiModel(DFM_tfidf,
                                   id2word = dictionary_clean,
                                   num_topics = 10)
SVD=SVD_model[DFM_tfidf]
SVD_result = pd.DataFrame(gensim.matutils.corpus2csc(SVD).T.toarray())
SVD_result

"""Topic Modeling"""

n_topics = 5
ldamodel = gensim.models.LdaModel(DFM_clean,
                                  num_topics=n_topics,
                                  id2word = dictionary_clean,
                                  passes=20)

import pyLDAvis
pyLDAvis.enable_notebook()

import pyLDAvis.gensim_models
vis = pyLDAvis.gensim_models.prepare(ldamodel,DFM_clean,dictionary_clean)
vis

"""Similarity and Clustering"""

from gensim.similarities import MatrixSimilarity
from scipy.cluster import hierarchy
import matplotlib.pyplot as plt
# doc term matrix instead of tfidf = no penalty for idf

index = MatrixSimilarity(DFM_clean,
                         num_features=len(dictionary_clean))
distance = 1-index[DFM_clean]

Z = hierarchy.linkage(distance, 'single')
plt.figure(figsize=(10,8))
#plt.ylim([.4,1.5])
dn = hierarchy.dendrogram(Z, orientation='right',leaf_font_size=11)

text_sim = pd.DataFrame(index[DFM_clean])
text_sim[0].sort_values(ascending=False)

from gensim.models import Word2Vec
model = Word2Vec(corpus_clean,min_count=1)

sim=model.wv.most_similar('hay',topn=17)
sim